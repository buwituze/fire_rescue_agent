[
    {
        "model_name": "DQN",
        "algorithm": "DQN",
        "mean_reward": 93.15899999999998,
        "std_reward": 27.926478277792203,
        "success_rate": 0.9,
        "success_count": 45,
        "mean_episode_length": 42.6,
        "mean_wall_collision_rate": 0.013333333333333332,
        "mean_scan_efficiency": 0.02,
        "mean_pickup_attempts": 1.8,
        "mean_time_to_find_survivor": 9.533333333333333,
        "num_episodes": 50
    },
    {
        "model_name": "A2C",
        "algorithm": "A2C",
        "mean_reward": 29.55599999999978,
        "std_reward": 146.7393406145736,
        "success_rate": 0.0,
        "success_count": 0,
        "mean_episode_length": 250.0,
        "mean_wall_collision_rate": 0.2320083523462621,
        "mean_scan_efficiency": 0.8,
        "mean_pickup_attempts": 0.0,
        "mean_time_to_find_survivor": 101.82608695652173,
        "num_episodes": 50
    },
    {
        "model_name": "REINFORCE",
        "algorithm": "REINFORCE",
        "mean_reward": 0.14400000000000646,
        "std_reward": 0.2957093167284389,
        "success_rate": 0.0,
        "success_count": 0,
        "mean_episode_length": 250.0,
        "mean_wall_collision_rate": 0.0,
        "mean_scan_efficiency": 0.0,
        "mean_pickup_attempts": 0.0,
        "mean_time_to_find_survivor": null,
        "num_episodes": 50
    },
    {
        "model_name": "PPO",
        "algorithm": "PPO",
        "mean_reward": -0.10879999999984363,
        "std_reward": 151.19682652278095,
        "success_rate": 0.72,
        "success_count": 36,
        "mean_episode_length": 95.36,
        "mean_wall_collision_rate": 0.32711791952796865,
        "mean_scan_efficiency": 0.0,
        "mean_pickup_attempts": 1.56,
        "mean_time_to_find_survivor": 19.214285714285715,
        "num_episodes": 50
    }
]